apiVersion: batch/v1
kind: Job
metadata:
  name: ocp-on-rhv-full-conformance
  labels:
    jobgroup: ansible-runner
spec:
  backoffLimit: 0
  template:
    metadata:
      name: ocp-on-rhv-full-conformance
      labels:
        jobgroup: ansible-runner
    spec:
      backoffLimit: 0
      terminationGracePeriodSeconds: 900
      containers:

      - name: lease
        image: registry.svc.ci.openshift.org/ci/boskoscli:latest
        terminationMessagePolicy: FallbackToLogsOnError
        resources:
          requests:
            cpu: 10m
            memory: 10Mi
          limits:
            memory: 200Mi
        volumeMounts:
        - name: shared-tmp
          mountPath: /tmp/shared
        - name: cluster-profile
          mountPath: /etc/openshift-installer
        - name: installer-artifacts
          mountPath: /tmp/artifacts
        env:
        - name: CLUSTER_TYPE
          value: "ovirt"
        - name: CLUSTER_NAME
          value: "ovirt-manual-run"
        - name: LEASE_TYPE
          value: "conformance"


        command:
        - /bin/bash
        - -c
        - |
          #!/bin/bash
          set -euo pipefail

          trap 'rc=$?; CHILDREN=$(jobs -p); if test -n "${CHILDREN}"; then kill ${CHILDREN} && wait; fi; if test "${rc}" -ne 0; then touch /tmp/shared/exit; fi; exit "${rc}"' EXIT

          # hack for bazel
          function boskosctl() {
            /app/boskos/cmd/cli/app.binary "${@}"
          }

          function extract_leases_info() {
            echo "$( jq ."${1}" --raw-output "${2}" )"
          }

          function acquire_lease() {
            resource="$( boskosctl --server-url http://boskos.ci --owner-name "${CLUSTER_NAME}" acquire --type "${CLUSTER_TYPE}-quota-slice" --state "free" --target-state "leased" --timeout 150m )"
            resource_name="$(echo "${resource}"|jq .name --raw-output)"
            lease_path="/etc/openshift-installer/${resource_name}.json"
            ovirt_engine_template_name="$(extract_leases_info ovirt_engine_template_name ${lease_path})"
            if [ "${LEASE_TYPE}" == "conformance" ]; then
              bm_name="$(extract_leases_info ovirt_engine_cluster_bm ${lease_path})"
              conformance_resource="$( boskosctl --server-url http://boskos.ci --owner-name "${CLUSTER_NAME}" acquire --type "${CLUSTER_TYPE}-${bm_name}" --state "free" --target-state "leased" --timeout 150m )"
              conformance_resource_name="$(echo "${conformance_resource}"|jq .name --raw-output)"
              worker_cpu=8
              worker_mem=16384
              master_cpu=8
              master_mem=16384
            else
              ovirt_engine_template_name="${ovirt_engine_template_name}-8G"
              worker_cpu=4
              worker_mem=8192
              master_cpu=4
              master_mem=8192
            fi
          }

          echo "[INFO] Acquiring a lease ..."
          acquire_lease

          #Saving parameters for the env
          cat > /tmp/shared/ovirt-lease.conf <<EOF
          OVIRT_APIVIP="$(extract_leases_info ovirt_apivip ${lease_path})"
          OVIRT_DNSVIP="$(extract_leases_info ovirt_dnsvip ${lease_path})"
          OVIRT_INGRESSVIP="$(extract_leases_info ovirt_ingressvip ${lease_path})"
          WORKER_CPU="${worker_cpu}"
          WORKER_MEM="${worker_mem}"
          MASTER_CPU="${master_cpu}"
          MASTER_MEM="${master_mem}"
          OCP_CLUSTER="$(extract_leases_info cluster_name ${lease_path})"
          OVIRT_ENGINE_CLUSTER_ID="$(extract_leases_info ovirt_engine_cluster_id ${lease_path})"
          OVIRT_ENGINE_TEMPLATE_NAME="${ovirt_engine_template_name}"
          EOF

          touch /tmp/shared/leased
          echo "[INFO] Lease acquired!"
          echo "[INFO] Leased resource: ${resource}"

          function release() {
              echo "killing heartbeat process "${1}""
              kill -9 "${1}"
              echo "[INFO] Releasing the lease on resouce ${resource_name}"
              boskosctl --server-url http://boskos.ci --owner-name "${CLUSTER_NAME}" release --name "${resource_name}" --target-state "free"
              if [ "${LEASE_TYPE}" == "conformance" ]; then
                echo "[INFO] Releasing the lease on resouce ${conformance_resource_name}"
                boskosctl --server-url http://boskos.ci --owner-name "${CLUSTER_NAME}" release --name "${conformance_resource_name}" --target-state "free"
              fi
          }

          echo "[INFO] Sending heartbeats to retain the lease..."
          boskosctl --server-url http://boskos.ci --owner-name "${CLUSTER_NAME}" heartbeat --resource "${resource}" &
          heartbeats_pid=$!

          trap "release "${heartbeats_pid}"" EXIT
          trap 'release "${heartbeats_pid}"' TERM

          while true; do
            if [[ -f /tmp/shared/exit ]]; then
              echo "Another process exited" 2>&1
              exit 0
            fi

            sleep 15 & wait $!
          done




      - name: setup
        #image: quay.io/rgolangh/openshift-installer@sha256:b06c67502f9d9abaffebe3cccc606815c6d26a3df0c306fed90b5c4267a9cfd1
        image: quay.io/rgolangh/openshift-installer:latest
        terminationMessagePolicy: FallbackToLogsOnError
        volumeMounts:
        - name: shared-tmp
          mountPath: /tmp/shared
        - name: cluster-profile
          mountPath: /etc/openshift-installer
        - name: installer-artifacts
          mountPath: /tmp/artifacts
        env:
        - name: SSH_PUB_KEY_PATH
          value: /etc/openshift-installer/ssh-publickey
        - name: PULL_SECRET_PATH
          value: /etc/openshift-installer/pull-secret
        - name: USER
          value: test
        - name: HOME
          value: /tmp

        command:
        - /bin/sh
        - -c
        - |
          #!/bin/sh
          trap 'rc=$?; if test "${rc}" -eq 0; then touch /tmp/shared/01_install.done; else touch /tmp/shared/01_install.exit; fi; exit "${rc}"' EXIT
          trap 'CHILDREN=$(jobs -p); if test -n "${CHILDREN}"; then kill ${CHILDREN} && wait; fi' TERM

          while true; do
          if [[ -f /tmp/shared/exit ]]; then
            echo "Another process exited" 2>&1
            exit 1
          fi
          if [[ -f /tmp/shared/leased ]]; then
            echo "Lease acquired, installing..."
            break
          fi
          sleep 15 & wait
          done


          cp "$(command -v openshift-install)" /tmp
          mkdir -p /tmp/artifacts/installer



          #update the IDs for new cluster
          source /tmp/shared/ovirt-lease.conf
          source /etc/openshift-installer/ovirt.conf


          export PATH=$PATH:/tmp/shared
          export EXPIRATION_DATE=$(date -d '4 hours' --iso=minutes --utc)
          export SSH_PUB_KEY=$(cat "${SSH_PUB_KEY_PATH}")
          export PULL_SECRET=$(cat "${PULL_SECRET_PATH}")
          export TF_VAR_ovirt_template_mem=${WORKER_MEM}
          export TF_VAR_ovirt_template_cpu=${WORKER_CPU}
          export TF_VAR_ovirt_master_mem=${MASTER_MEM}
          export TF_VAR_ovirt_master_cpu=${MASTER_CPU}




          #export OVIRT_CONFIG=/tmp/ovirt.conf
          export OPENSHIFT_INSTALL_OS_IMAGE_OVERRIDE=${OVIRT_ENGINE_TEMPLATE_NAME}

          # We want the setup to download the latest CA from the engine
          # Therefor living it empty
          export OVIRT_CONFIG=/tmp/artifacts/installer/ovirt-config.yaml
          cat > /tmp/artifacts/installer/ovirt-config.yaml <<EOF
          ovirt_url: ${OVIRT_ENGINE_URL}
          ovirt_username: ${OVIRT_ENGINE_USERNAME}
          ovirt_password: ${OVIRT_ENGINE_PASSWORD}
          ovirt_cafile: ""
          ovirt_insecure: true
          EOF

          cat > /tmp/artifacts/installer/install-config.yaml << EOF
          apiVersion: v1
          baseDomain: ${BASE_DOMAIN}
          metadata:
            name: ${OCP_CLUSTER}
          compute:
          - hyperthreading: Enabled
            name: worker
            platform: {}
            replicas: 2
          controlPlane:
            hyperthreading: Enabled
            name: master
            platform: {}
            replicas: 3
          platform:
            ovirt:
              ovirt_cluster_id: ${OVIRT_ENGINE_CLUSTER_ID}
              ovirt_storage_domain_id: ${OVIRT_ENGINE_STORAGE_DOMAIN_ID}
              api_vip: ${OVIRT_APIVIP}
              dns_vip: ${OVIRT_DNSVIP}
              ingress_vip: ${OVIRT_INGRESSVIP}
          pullSecret: >
            ${PULL_SECRET}
          sshKey: |
            ${SSH_PUB_KEY}
          EOF

          export OPENSHIFT_INSTALL_RELEASE_IMAGE_OVERRIDE=registry.svc.ci.openshift.org/ocp/release:4.4-ci
          #4.4.0-0.nightly-2020-02-06-012716
          #export OPENSHIFT_INSTALL_RELEASE_IMAGE_OVERRIDE=registry.svc.ci.openshift.org/ocp/release:4.4.0-0.nightly-2020-02-06-012716
          #export OPENSHIFT_INSTALL_RELEASE_IMAGE_OVERRIDE=registry.svc.ci.openshift.org/ocp/release:4.4.0-0.nightly-2020-02-10-111955


          function update_image_registry() {
            while true; do
              sleep 10;
              oc get configs.imageregistry.operator.openshift.io/cluster >/dev/null 2>&1 && break
            done
            oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch '{"spec":{"managementState":"Managed","storage":{"emptyDir":{}}}}'
          }


          cd /tmp/artifacts
          #download oc if missing
          if [ ! -f oc ] ; then
            echo "downloading oc binary"
            wget https://github.com/openshift/origin/releases/download/v3.11.0/openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit.tar.gz -O oc-latest-linux-64bit.tar.gz
            tar xvfz oc-latest-linux-64bit.tar.gz
            find ./ -type f -name oc | xargs -I {} mv {} oc
            rm -rf openshift*
            rm -rf *.tar.gz
            chmod +x ./oc
          fi
          export PATH=$PATH:/tmp/artifacts

          TF_LOG=debug openshift-install --dir=/tmp/artifacts/installer create ignition-configs --log-level=debug
          python -c \
              'import json, sys; j = json.load(sys.stdin); j[u"systemd"][u"units"] = [{u"contents": "[Unit]\nDescription=Mount etcd as a ramdisk\nBefore=local-fs.target\n[Mount]\n What=none\nWhere=/var/lib/etcd\nType=tmpfs\nOptions=size=2G\n[Install]\nWantedBy=local-fs.target", u"enabled": True, u"name":u"var-lib-etcd.mount"}]; json.dump(j, sys.stdout)' \
              </tmp/artifacts/installer/master.ign \
              >/tmp/artifacts/installer/master.ign.out
          mv /tmp/artifacts/installer/master.ign.out /tmp/artifacts/installer/master.ign

          export KUBECONFIG=/tmp/artifacts/installer/auth/kubeconfig
          update_image_registry &

          # What we're doing here is we generate manifests first and force that OpenShift SDN is configured.
          TF_LOG=debug openshift-install --dir=/tmp/artifacts/installer create manifests --log-level=debug
          TF_LOG=debug openshift-install --dir=/tmp/artifacts/installer create cluster --log-level=debug &
          wait "$!"

          install_exit_status=$?
          export KUBECONFIG=/tmp/artifacts/installer/auth/kubeconfig

          sleep 10m
          ./oc get co/image-registry

          exit $install_exit_status



      - name: run-conformance-tests
        #image: quay.io/rgolangh/openshift-installer@sha256:b06c67502f9d9abaffebe3cccc606815c6d26a3df0c306fed90b5c4267a9cfd1
        image: 'registry.svc.ci.openshift.org/ovirt/openshift-tests:eslutsky'
        imagePullPolicy: IfNotPresent
        terminationMessagePolicy: FallbackToLogsOnError
        resources:
          requests:
            cpu: 1
            memory: 1Gi
          limits:
            memory: 7Gi
        command:
        - /bin/sh
        - -c
        - |
          #!/bin/bash
          trap 'rc=$?;  touch /tmp/shared/02_tests.done ; exit "${rc}"' EXIT
          trap 'CHILDREN=$(jobs -p); if test -n "${CHILDREN}"; then kill ${CHILDREN} && wait; fi' TERM

          set -euo pipefail

          echo "waiting for installation to complete..."
          for i in $(seq 1 180); do
            if [[ -f /tmp/shared/01_install.done ]]; then
              break
            fi
            sleep 20 & wait
          done
          echo "beginnging testing..."

          export KUBECONFIG=/tmp/artifacts/installer/auth/kubeconfig
           cd /tmp/artifacts
          #wget https://storage.googleapis.com/origin-ci-test/pr-logs/pull/openshift_release/4340/rehearse-4340-pull-ci-openshift-installer-master-e2e-ovirt/202/artifacts/e2e-ovirt/installer/auth/kubeconfig
          #export KUBECONFIG=/tmp/artifacts/kubeconfig

          mkdir -p output/

          if [ ! -f $KUBECONFIG ] ; then
            echo -e "Couldnt find KUBECONFIG at $KUBECONFIG"
            exit 22
          fi

          openshift-tests run openshift/conformance/parallel -o run_conformance.log --junit-dir junit/


        volumeMounts:
        - name: config-gcp-secrets
          mountPath: /runner/gcp-secrets
        - name: shared-tmp
          mountPath: /tmp/shared
        - name: installer-artifacts
          mountPath: /tmp/artifacts
        - name: cluster-profile
          mountPath: /etc/openshift-installer

      - name: artifacts-pusher
        image: quay.io/eslutsky/ansible-runner
        #image: registry.svc.ci.openshift.org/ci/boskoscli
        #command: ["/bin/bash"]
        #args: ["-c","sleep 100000"]
        #args: ["apply","-auto-approve","ocp-on-rhv-ci"]
        command:
        - /bin/bash
        - -c
        - |
          #!/bin/bash
          set -euo pipefail


          if [ `id -u` -ge 500 ]; then
              echo "runner:x:`id -u`:`id -g`:,,,:/runner:/bin/bash" > /tmp/passwd
              cat /tmp/passwd >> /etc/passwd
              rm /tmp/passwd
          fi


          echo "waiting for installlation and testing to complete..."

          # wait for the installation to finish
          for i in $(seq 1 180); do
            if [[ -f /tmp/shared/02_tests.done ]]; then
              break
            fi
            sleep 60 & wait
          done
          date

          source /tmp/shared/ovirt-lease.conf
          mkdir -p ~/.ssh/
          chmod 700 ~/.ssh/

          cat <<__EOF__ >>~/.ssh/config
          Host *
            StrictHostKeyChecking no
          __EOF__
          chmod 400 ~/.ssh/config

          #push artifacts for engine/ci for audit
          cd /tmp/artifacts/
          if [ -f run_conformance.log ] ; then
            export ocp_cluster_id=$OCP_CLUSTER
            mkdir ${OCP_CLUSTER}/
            mv -f {run_conformance.log,junit,installer} ${OCP_CLUSTER}/
            ssh -i /runner/gcp-secrets/id_rsa centos@engine.rhv.gcp.devcluster.openshift.com "rm -rf /var/www/html/ci/${OVIRT_CLUSTER_NAME_P}"
            scp -i /runner/gcp-secrets/id_rsa  -r ${OCP_CLUSTER} centos@engine.rhv.gcp.devcluster.openshift.com:/var/www/html/ci/${OVIRT_CLUSTER_NAME_P}
          fi

          cd /tmp/scripts

          sleep 100000

          bash -x ./teardown-with-ansible.sh
          touch /tmp/shared/exit

        volumeMounts:
        - name: config-gcp-secrets
          mountPath: /runner/gcp-secrets
        - name: shared-tmp
          mountPath: /tmp/shared
        - name: installer-artifacts
          mountPath: /tmp/artifacts
        - name: cluster-profile
          mountPath: /etc/openshift-installer
        - name: scripts
          mountPath: /tmp/scripts
        env:
        - name: OVIRT_CLUSTER_NAME_P
          value: "ovirt05"

      volumes:
        - name: config-gcp-secrets
          secret:
            secretName: ovirt-infra-gcp-secrets

        - name: cluster-profile
          projected:
            sources:
            - secret:
                name: cluster-secrets-ovirt-test
            - secret:
                name: ovirt-infra-secrets

        - name: shared-tmp
          emptyDir: {}
        - name: installer-artifacts
          emptyDir: {}

        - name: scripts
          configMap:
            name: ocp-on-rhv-ci-scripts

      restartPolicy: Never
